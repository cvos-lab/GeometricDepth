Geometric and Background Channel Fusion for 3D Reconstruction
This repository contains the official code and dataset benchmarks for the paper "Geometric and Background Channel Fusion: Advancing Deep Fringe-to-Depth 3D Reconstruction".

We propose a physics-informed deep learning framework for single-shot Fringe Projection Profilometry (FPP). By fusing raw fringe patterns with geometric coordinate maps and background context, this method significantly improves reconstruction accuracy.

Key Features:

Multi-Channel Input Generation: Scripts to generate texture, difference maps, and geometric coordinates.

Model Architectures: Complete PyTorch implementations of HiDNet, MSUNet++, and MSAUNet.

Evaluation: Pre-trained weights and testing scripts for quantitative benchmarking (MAE, RMSE, Accuracy).
